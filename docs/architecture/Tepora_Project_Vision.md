# Tepora プロジェクトビジョン

## 1. コアビジョン：技術の民主化と個人のためのAI

Teporaの根底にあるのは、**「高度なAI技術を、巨大企業のクラウドから個人の手に取り戻す」**という精神です。
予算ゼロ、単一のコンシューマーGPUという制約の中から、無限の可能性を模索する純粋な探求心からこのプロジェクトは始まりました。

*   **ローカル・ソブリンティ (主権):** ユーザーのデータとプライバシーは、ユーザー自身のハードウェアの中に留まるべきです。外部への依存を排除し、真の意味でユーザーのために働くAIを目指します。
*   **制約からの創造:** 限られたリソース（単一GPU）は、制限ではなく、創造性を生むための制約です。この制約の中で、いかに効率的かつ高度な知能を実現するかが、私たちの技術的挑戦の核心です。
*   **強靭な自律性:** インターネットさえも前提としない環境で、自律的に思考し、行動できる強さを持ちます。

## 2. 目指すべきアーキテクチャ：「単一GPU上のマルチエージェント」

本プロジェクトの最終目標は、限られたリソースの中で、役割の異なる複数のAIエージェントが協調して動作する、まるで「チーム」のようなシステムです。

### 2.1. 役割の専門化と協調
特定のモデル名に依存せず、役割に応じた最適なモデルを適材適所で組み合わせます。
*   **マネージャー・エージェント:**
    *   ユーザーとの対話、タスクの分解、計画立案を担当します。
    *   全体を俯瞰し、軽量かつ高速に判断を下す「指揮官」の役割を果たします。
*   **プロフェッショナル・エージェント:**
    *   複雑なツールの実行、専門的な知識の提供、長文脈の理解を担当します。
    *   必要に応じて呼び出される、特定分野の「達人」の役割を果たします。

### 2.2. 動的リソース管理（動的な知能のロード）
ハードウェアの物理的な限界を超えるため、必要な瞬間に必要な知能（モデル）を動的にロード・アンロードする仕組みを構築します。これにより、小さなハードウェアで巨大な知能を扱うことを可能にします。

### 2.3. 機械の記憶から「エピソード」へ
単なるログやデータの蓄積ではない、人間の記憶に近い**エピソード記憶 (EM-LLM)**の実装を目指します。
文脈を理解し、過去の経験から学び、ユーザーと共に成長するAIを実現します。

## 3. 実現のための技術戦略

Teporaのビジョンを実現するために採択された、具体的な技術的アプローチです。（※詳細な設計原則・哲学については [Tepora_Design_Philosophy.md](./Tepora_Design_Philosophy.md) を参照）

*   **戦略1: 安定性と互換性の重視**
    *   ビジョンにある「コンシューマーハードウェアでの動作」を確実にするため、理論上の最高速度よりも、Windows環境での安定稼働を優先します。
    *   具体的には、最先端だが不安定なライブラリよりも、コミュニティに支持された堅牢な技術（Transformers, bitsandbytes）を選択します。
*   **戦略2: エコシステムへの準拠 (LangChain Native)**
    *   車輪の再発明を避け、AI界隈の標準的なプロトコルやライブラリ（LangChain, MCP）に深く準拠します。
    *   これにより、独自のハックに頼ることなく、AIモデルが持つ本来の能力（Instruction Followingなど）を自然な形で引き出します。
*   **戦略3: 制御フローの透明化 (LangGraph)**
    *   自律型AIの挙動をブラックボックス化せず、ユーザーが理解・介入できるようにします。
    *   LangGraphを用いて思考プロセスを可視化し、「なぜその行動をとったのか」を追跡可能にすることで、人とAIの信頼関係を技術的に担保します。
