"""
エージェント全体の設定値を集約するモジュール。

役割:
- モデルIDや生成パラメータなど、LLM関連の設定
- ネイティブツールの挙動設定(例: DuckDuckGoの結果数)
- プロンプトテンプレート群(REACT/ダイレクト回答/検索要約など)
- MCP(Multi-Server Client Protocol)の設定ファイルパス

注意:
- 実行時に値を参照するため、ここでの変更はアプリ全体の挙動に影響します。
"""

# agent_core/config.py
import os
from pathlib import Path
from typing import List
from langchain_core.tools import BaseTool
from dotenv import load_dotenv

load_dotenv()


# --- Model Configuration ---
GEMMA_3N_MODEL_ID = "google/gemma-3n-e4b-it"  # Gemma 3N のモデルID
JAN_NANO_MODEL_ID = "Menlo/Jan-nano-128k"     # jan-nano-128k のモデルID
#GGUF_MODEL_PATH = Path(r"E:\AIagent_Project\gemma-3n-E4B-it-Q4_K_M.gguf") # 将来用

USE_4BIT_QUANTIZATION = False              # Gemma 3N で共通的に4bit量子化を使うか
USE_GEMMA_3N_4BIT_QUANTIZATION = False     # Gemma 3N個別の量子化フラグ
USE_JAN_NANO_4BIT_QUANTIZATION = True      # jan-nano個別の量子化フラグ

#モデルごとに生成パラメータを分離 
GEMMA_PARAMS = {
    "temperature": 1,
    "top_p": 0.95,
    "top_k": 64,
    "max_new_tokens": 4096,
}

JAN_PARAMS = {
    "temperature": 0.7,
    "top_p": 0.8, 
    "top_k": 20,
    "max_new_tokens": 4096,
}

# --- Memory Configuration ---
SHORT_TERM_MEMORY_WINDOW_SIZE = 20  # 短期メモリとして保持する発話数の上限
MAX_CHAT_HISTORY_LENGTH = 40  #チャット履歴の最大長
# --- Native Tool Configuration ---

# Google Custom Search API Configuration
# 環境変数から取得
GOOGLE_CUSTOM_SEARCH_API_KEY = os.getenv('GOOGLE_CUSTOM_SEARCH_API_KEY')
GOOGLE_CUSTOM_SEARCH_ENGINE_ID = os.getenv('GOOGLE_CUSTOM_SEARCH_ENGINE_ID')
# キーが存在しない場合にエラーを発生させ、起動を安全に停止させる
if not GOOGLE_CUSTOM_SEARCH_API_KEY or not GOOGLE_CUSTOM_SEARCH_ENGINE_ID:
    raise ValueError("API keys for Google Custom Search are not set in the .env file.")

GOOGLE_CUSTOM_SEARCH_MAX_RESULTS = 10 #int(os.getenv('GOOGLE_CUSTOM_SEARCH_MAX_RESULTS', '10'))

# タイムアウト設定
GOOGLE_CUSTOM_SEARCH_CONNECT_TIMEOUT = 10  # 接続タイムアウト（秒）
GOOGLE_CUSTOM_SEARCH_READ_TIMEOUT = 30     # 読み取りタイムアウト（秒）

# リトライ設定
GOOGLE_CUSTOM_SEARCH_MAX_RETRIES = 3       # 最大リトライ回数
GOOGLE_CUSTOM_SEARCH_BACKOFF_FACTOR = 1    # バックオフ係数


# --- Prompt Engineering ---

#ReActプロンプト用に、ツールのリストを「名前: 説明」の形式で整形する
def format_tools_for_react_prompt(tools: List[BaseTool]) -> str:
    """
    ReActプロンプトのために、ツール一覧を人が読みやすいシグネチャ形式の文字列に整形する。

    例:
      - tool_name(arg1: string, arg2: number): 説明
    """
    tool_strings = []
    for tool in tools:
        args_schema = getattr(tool, 'args', {})
        args_repr = ", ".join(
            f"{name}: {details.get('type', 'any')}"
            for name, details in args_schema.items()
        )
        tool_strings.append(f"  - {tool.name}({args_repr}): {tool.description}")
    return "\n".join(tool_strings)
# 役割に応じた3種類のシステムプロンプトを定義
DIRECT_ANSWER_SYSTEM_PROMPT = "You are a helpful and friendly AI assistant named Gemma. Respond to the user in a conversational manner."

SEARCH_SUMMARY_SYSTEM_PROMPT = """You are a search summarization expert.
Your task is to synthesize the provided search results to answer the user's original question.
Provide a clear, concise, and comprehensive answer based on the information given. Your answer should be based *only* on the search results.
However, if the search results do not contain the necessary information, you may answer from your own knowledge. If you do so, you MUST explicitly state that the information is from your own knowledge.
The response MUST be in the same language as the user's original question."""

SYNTHESIS_SYSTEM_PROMPT = """You are a communications specialist AI. Your primary role is to act as a friendly and clear interface for the user.
You will be given a technical report generated by an autonomous agent that has completed a task.
Your mission is to translate this internal, technical report into a polished, natural-sounding, and easy-to-understand response for the user.

**Key Instructions:**
- **Translate, Don't Just Repeat:** Rephrase the technical findings into a conversational response.
- **User's Language:** The final response MUST be in the same language as the user's original request.
- **Omit Jargon:** Do NOT include technical jargon like "thought", "observation", "action", or tool names unless it is absolutely essential for the final answer.
- **Focus on the Outcome:** Emphasize the final result and key findings, not the step-by-step process the agent took.
"""

REACT_SYSTEM_PROMPT = """You are a powerful, autonomous AI agent operating in "Agent Mode".
Your primary goal is to achieve the user's objective by reasoning step-by-step and utilizing a set of available tools.

**Core Directives:**
1.  **Think First:** Always start with a "thought" that clearly explains your reasoning, analysis of the situation, and your plan for the next step.
2.  **Use Tools Correctly:** You have access to the tools listed below. You MUST use them according to their specified schema.
3.  **Strict JSON Format:** Your entire output MUST be a single, valid JSON object. Do not include any text outside of the JSON structure.
4.  **Observe and Iterate:** After executing a tool, you will receive an "observation" containing the result. Analyze this observation to inform your next thought and action.
5.  **FINISH IS NOT A TOOL:** To end the process, you MUST use the `finish` key in your JSON response. The `finish` key is a special command to signal that your work is done; it is NOT a callable tool.

**AVAILABLE TOOLS SCHEMA:**
{tools}

**RESPONSE FORMAT:**

**1. To use a tool:**
```json
{{
  "thought": "Your detailed reasoning and step-by-step plan.",
  "action": {{
    "tool_name": "the_tool_to_use",
    "args": {{
      "argument_name": "value"
    }}
  }}
}}
```

**2. To finish the task and generate your report:**
```json
{{
  "thought": "I have collected all necessary information. I will now create a technical summary of my findings.",
  "finish": {{
    "answer": "(A technical summary of the execution process and results. This will be passed to another AI to formulate the final user-facing response.)"
  }}
}}
```
"""

# --- MCP Configuration ---
MCP_CONFIG_FILE = "mcp_tools_config.json"  # MCP接続設定ファイル名(プロジェクトルート基準)