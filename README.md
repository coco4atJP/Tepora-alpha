
![Tepora log](https://github.com/coco4atJP/tepora-alpha/blob/main/Tepora_logo.png)

# Tepora â€“ Multiâ€‘AI Agent System (Alpha v1.1)

Tepora is a modular framework designed to build a sophisticated, conversational multiâ€‘agent AI system. The project
leverages local LLMs, dynamic resource management, and an extensible tool ecosystem to create powerful, autonomous
agents.

---

## âœ¨ Core Features

- **Multiâ€‘Agent Architecture** â€“ Twoâ€‘agent design:
  - **Character Agent (`Gemmaâ€‘3N`)** â€“ Acts as a persona that converses with the user. In agent mode it
interprets user requests, creates a structured JSON â€œorderâ€, and reports the final outcome back to the user.
  - **Executor Agent (`Janâ€‘nano`)** â€“ A professional, practical agent that executes orders using a ReAct (reason
+ act) loop.
- **Dynamic LLM Management** â€“ `LLMManager` dynamically loads/unloads GGUF models to VRAM or RAM, enabling the
use of multiple powerful models even on consumerâ€‘grade GPUs or CPUs.
- **Extensible Tool System** â€“ `ToolManager` integrates:
  - **Native Tools** â€“ Pythonâ€‘based tools such as `GoogleCustomSearchTool`.
  - **MCP (Multiâ€‘Server Client Protocol) Tools** â€“ A custom protocol that lets the agent communicate with tools
running in separate processes, enabling languageâ€‘agnostic tool development.
- **Stateful Graphâ€‘Based Execution** â€“ Agent logic is defined as a state graph on top of LangGraph, enabling
complex conditional flows for a variety of user commands.
- **Multiple Interaction Modes**:
  - **Direct Chat** â€“ Simple, straightforward conversation.
  - **Search Mode (`/search`)** â€“ A dedicated flow for web search and summarisation.
  - **Agent Mode (`/agentmode`)** â€“ Runs a full multiâ€‘agent ReAct loop for complex tasks.
- **Configurationâ€‘Driven** â€“ Prompts, model parameters, API keys, and tool settings are centrally configured.

---

## ğŸ—ï¸ Architecture Overview

The application follows a stateâ€‘driven, graphâ€‘based execution model.

1. **`main.py`** â€“ Entry point. Initializes `LLMManager`, `ToolManager`, and the `AgentCore` graph. Then enters a
CLI loop that accepts user input.
2. **`agent_core/graph.py`** â€“ Core agent logic using LangGraph.
   - **Routing** â€“ `route_by_command` directs user input to one of three main branches (`direct_answer`,
`search`, `agent_mode`).
   - **Agentâ€‘Mode Flow**:
     1. `generate_order_node` â€“ Character agent (Gemma) creates a JSON plan.
     2. `agent_reasoning_node` â€“ Executor agent (Janâ€‘nano) starts a ReAct loop to execute the plan using tools.
     3. `tool_node` â€“ The chosen tool is executed via `ToolManager`.
     4. `synthesize_final_response_node` â€“ Once the ReAct loop finishes, a technical report is transformed into a
userâ€‘friendly response.
3. **`agent_core/llm_manager.py`** â€“ Manages the LLM lifecycle. Models are loaded into GPU VRAM or CPU RAM only
when needed, and unloaded afterward to free resources, enabling the use of different models for different tasks.
4. **`agent_core/tool_manager.py`** â€“ Unified interface for all tools. Detects and manages both native Python
tools and external MCPâ€‘connected tools, handling both synchronous and asynchronous execution.

---

## ğŸš€ Getting Started

### Prerequisites

- **Python â‰¥â€¯3.10** (Pythonâ€¯3.12 was used for development)
- CUDAâ€‘compatible NVIDIA GPU or ROCmâ€‘compatible AMD GPU for faster inference. CPUâ€‘only mode is available but
slower.
- **Node.js** â€“ required for running many MCP servers.
- **Git**

### Minimum System Specs

- â‰¥â€¯7.5â€¯GB free disk space
- â‰¥â€¯16â€¯GB RAM or â‰¥â€¯6â€¯GB VRAMâ€¯â€“â€¯RAM or VRAM is required for the MCP servers and loaded LLMs. Reducing
`llama.cpp`â€™s `n_ctx` can lower RAM usage but may affect performance. <sub>See notes above.</sub>
- A compute environment supported by `Llamaâ€‘cppâ€‘python`.

### Installation

1. **Clone the repository:**
   ```bash
   git clone https://github.com/username/repository.git AIagent_Project_1
   cd AIagent_Project_1
   ```

2. **Install dependencies** (virtual environment is recommended):
   ```bash
   python -m venv venv
   source venv/bin/activate        # Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Set up environment variables:**
   Copy the example file and create a `.env` in the project root:
   ```bash
   cp .env.example .env
   ```
   Edit `.env` to add your API keys:
   ```dotenv
   # .env
   GOOGLE_CUSTOM_SEARCH_API_KEY="your_google_api_key"
   GOOGLE_CUSTOM_SEARCH_ENGINE_ID="your_google_cx_id"
   ```

### Running the Agent

Start the agent from the project root:
```bash
python main.py
```

---

## ğŸ¤– Usage

Once the agent is running, interact via the terminal.

- **Direct chat:**
  ```
  YOU: Hello, how are you?
  ```

- **Search mode:**
  ```
  YOU: /search What is LangGraph?
  ```

- **Agent mode (for complex tasks):**
  ```
  YOU: /agentmode Find out the current price of Bitcoin and find the latest news.
  ```

- **Exit the application:**
  ```
  YOU: exit
  ```

---

## ğŸ§© Core Components

- **`main.py`** â€“ Entry point, initialization, and main conversation loop.
- **`agent_core/graph.py`** â€“ Defines the LangGraph execution graph, nodes, and edges. Contains all core logic
for the agent modes.
- **`agent_core/state.py`** â€“ Defines `AgentState` TypedDict for state passed between graph nodes.
- **`agent_core/llm_manager.py`** â€“ Handles dynamic loading/unloading of GGUF models to VRAM or RAM.
- **`agent_core/tool_manager.py`** â€“ Detects, manages, and provides an execution interface for all tools (native
and MCP).
- **`agent_core/config.py`** â€“ Centralised configuration for model paths, generation parameters, prompts,
personas, and API keys.

---

## ğŸ› ï¸ Tool System

Agents can use two types of tools.

### Native Tools

These are Python classes inheriting from `langchain_core.tools.BaseTool`, e.g., `GoogleCustomSearchTool`. They are
loaded directly by `ToolManager`.

### MCP (Multiâ€‘Server Client Protocol) Tools

Allows agents to use tools running in separate processes, languageâ€‘agnostic.

1. **Setup** â€“ Define tool servers in `mcp_tools_config.json`. Example (Claudeâ€‘Desktop style):
   ```json
   {
     "mcpServers": {
       "my_tool_server": {
         "command": "python",
         "args": ["-m", "path.to.your.tool_server"],
         "env": {}
       }
     }
   }
   ```

2. **Detection** â€“ `ToolManager` launches the processes defined in the config, connects via stdio, and discovers
the tools they provide using the MCP protocol.

3. **Naming** â€“ MCP tools are automatically named `server_name_tool_name` to avoid conflicts.

---

## âš™ï¸ Configuration

- **`.env`** â€“ Stores secrets (API keys, etc.). Not committed to version control.
- **`agent_core/config.py`** â€“ Main config file.
  - `MODELS_GGUF` â€“ Model paths and parameters. Generation defaults include temperature, Top.P, Top.K, and
max_tokens.
  - `PERSONA_PROMPTS` â€“ Different character personas for the character agent.By default, two types are provided: `souha_yoi` (å¥ç¾½ èŒ—ä¼Š) and `bunny_girl` (marina). Both are written in Japanese, so please change them as needed.
  - `ACTIVE_PERSONA` â€“ Currently selected persona.
  - `BASE_SYSTEM_PROMPTS` â€“ Core prompts for summarisation, ReAct reasoning, etc.
- **`mcp_tools_config.json`** â€“ Configures external tool servers.

---

## ğŸ—ºï¸ Roadmap

- [ ] Implement a more robust errorâ€‘recovery mechanism within the ReAct loop.
- [ ] Create a simple GUI.
- [ ] Expand the library of native and MCP tools.
- [ ] Add persistent memory/database integration to store longâ€‘term conversation history.

---

## ğŸ“œ License

This project is licensed under the MIT License. See the `LICENSE` file for details.

---
---

# Tepora - ãƒãƒ«ãƒAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (ã‚¢ãƒ«ãƒ•ã‚¡ç‰ˆ v1.1)

æ´—ç·´ã•ã‚ŒãŸãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå¯¾è©±å‹AIã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã™ã‚‹ãŸã‚ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¼ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã§ã™ã€‚ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«LLMã€å‹•çš„ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†ã€æ‹¡å¼µå¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚’æ´»ç”¨ã—ã€å¼·åŠ›ã§è‡ªå¾‹çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚

## âœ¨ ä¸»ãªæ©Ÿèƒ½

* **ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£**: 2ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­è¨ˆã‚’æ¡ç”¨:
* **ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (`Gemma-3N`)**: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã¨ã—ã¦ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨å¯¾è©±ã‚’ã—ã¾ã™ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è§£é‡ˆã—ã€æ§‹é€ åŒ–ã•ã‚ŒãŸJSONå½¢å¼ã®ã€Œã‚ªãƒ¼ãƒ€ãƒ¼ã€ã‚’ä½œæˆã—ã€æœ€çµ‚çš„ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®å ±å‘Šã‚’è¡Œã„ã¾ã™ã€‚
* **ã‚¨ã‚°ã‚¼ã‚­ãƒ¥ãƒ¼ã‚¿ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (`Jan-nano`)**: ReAct (æ¨è«–+è¡Œå‹•) ãƒ«ãƒ¼ãƒ—ã‚’ç”¨ã„ã¦ã‚ªãƒ¼ãƒ€ãƒ¼ã‚’å®Ÿè¡Œã™ã‚‹ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§å®Ÿç”¨çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€‚
* **å‹•çš„LLMç®¡ç†**: `LLMManager` ã¯ã€GGUFãƒ¢ãƒ‡ãƒ«ã‚’VRAMã¾ãŸã¯RAMã«å‹•çš„ã«ãƒ­ãƒ¼ãƒ‰/ã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒ³ã‚·ãƒ¥ãƒ¼ãƒãƒ¼ã‚°ãƒ¬ãƒ¼ãƒ‰ã®GPUã‚‚ã—ãã¯CPUä¸Šã§è¤‡æ•°ã®å¼·åŠ›ãªãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚
* **æ‹¡å¼µå¯èƒ½ãªãƒ„ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ **: `ToolManager` ã¯ä»¥ä¸‹ã‚’çµ±åˆã—ã¾ã™ã€‚
* **ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ„ãƒ¼ãƒ«**: `GoogleCustomSearchTool` ãªã©ã® Python ãƒ™ãƒ¼ã‚¹ã®ãƒ„ãƒ¼ãƒ«ã€‚
* **MCP (Multi-Server Client Protocol) ãƒ„ãƒ¼ãƒ«**: åˆ¥ãƒ—ãƒ­ã‚»ã‚¹ã¨ã—ã¦å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹ãƒ„ãƒ¼ãƒ«ã¨é€šä¿¡ã™ã‚‹ãŸã‚ã®ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã€‚è¨€èªã«ä¾å­˜ã—ãªã„ãƒ„ãƒ¼ãƒ«é–‹ç™ºã‚’å¯èƒ½ã«ã—ã¾ã™ã€‚
* **ã‚¹ãƒ†ãƒ¼ãƒˆãƒ•ãƒ«ãªã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®å®Ÿè¡Œ**: `LangGraph` ã‚’åŸºç›¤ã¨ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒ­ã‚¸ãƒƒã‚¯ã¯çŠ¶æ…‹ã‚°ãƒ©ãƒ•ã¨ã—ã¦å®šç¾©ã•ã‚Œã€ã•ã¾ã–ã¾ãªãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒãƒ³ãƒ‰ã«å¯¾ã—ã¦è¤‡é›‘ãªæ¡ä»¶ä»˜ããƒ•ãƒ­ãƒ¼ã‚’å®Ÿç¾ã—ã¾ã™ã€‚
* **è¤‡æ•°ã®ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ã‚·ãƒ§ãƒ³ãƒ¢ãƒ¼ãƒ‰**:
* **ãƒ€ã‚¤ãƒ¬ã‚¯ãƒˆãƒãƒ£ãƒƒãƒˆ**: ã‚·ãƒ³ãƒ—ãƒ«ã§ç›´æ¥çš„ãªä¼šè©±ãŒå¯èƒ½ã§ã™ã€‚
* **æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ (`/search`)**: Web æ¤œç´¢ã¨è¦ç´„å°‚ç”¨ã®ãƒ•ãƒ­ãƒ¼ã§ã™ã€‚
* **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ (`/agentmode`)**: è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ã®ãŸã‚ã«ã€å®Œå…¨ãªãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ ReAct ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
* **æ§‹æˆé§†å‹•å‹**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€API ã‚­ãƒ¼ã€ãƒ„ãƒ¼ãƒ«è¨­å®šã‚’ä¸€å…ƒçš„ã«æ§‹æˆã—ã¾ã™ã€‚

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¦‚è¦

ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€çŠ¶æ…‹é§†å‹•å‹ã®ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®å®Ÿè¡Œãƒ¢ãƒ‡ãƒ«ã«å¾“ã„ã¾ã™ã€‚

1. **`main.py`**: ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã€‚`LLMManager`ã€`ToolManager`ã€`AgentCore` ã‚°ãƒ©ãƒ•ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚ãã®å¾Œã€ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—ã«å…¥ã‚Šã€ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å—ã‘ä»˜ã‘ã¾ã™ã€‚
2. **`agent_core/graph.py`**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä¸­æ ¸éƒ¨åˆ†ã€‚`LangGraph` ã‚’ä½¿ç”¨ã—ã¦å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã‚’å®šç¾©ã—ã¾ã™ã€‚
* **ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°**: `route_by_command` é–¢æ•°ã¯ã€ã¾ãšãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’ 3 ã¤ã®ä¸»è¦ãªãƒ–ãƒ©ãƒ³ãƒ (`direct_answer`ã€`search`ã€`agent_mode`) ã®ã„ãšã‚Œã‹ã«èª˜å°ã—ã¾ã™ã€‚
* **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ãƒ•ãƒ­ãƒ¼**:
    1.  `generate_order_node`: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ (Gemma) ãŒ JSON ãƒ—ãƒ©ãƒ³ã‚’ä½œæˆã—ã¾ã™ã€‚
    2.  `agent_reasoning_node`: Executor Agent (Jan-nano) ã¯ã€ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦è¨ˆç”»ã‚’å®Ÿè¡Œã™ã‚‹ ReAct ãƒ«ãƒ¼ãƒ—ã‚’é–‹å§‹ã—ã¾ã™ã€‚
    3.  `tool_node`: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒ `ToolManager` ã‚’ä»‹ã—ã¦é¸æŠã—ãŸãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
    4.  `synthesize_final_response_node`: ReAct ãƒ«ãƒ¼ãƒ—ãŒå®Œäº†ã™ã‚‹ã¨ã€æœ€çµ‚çš„ãªæŠ€è¡“ãƒ¬ãƒãƒ¼ãƒˆãŒãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹ã«å¤‰æ›ã•ã‚Œã¾ã™ã€‚
3. **`agent_core/llm_manager.py`**: LLM ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ã‚’ç®¡ç†ã—ã¾ã™ã€‚å¿…è¦ãªå ´åˆã«ã®ã¿ãƒ¢ãƒ‡ãƒ«ã‚’ GPU VRAM ã‚‚ã—ãã¯ CPU RAM ã«ãƒ­ãƒ¼ãƒ‰ã—ã€ãã®å¾Œã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãƒªã‚½ãƒ¼ã‚¹ã‚’è§£æ”¾ã™ã‚‹ã“ã¨ã§ã€ç•°ãªã‚‹ã‚¿ã‚¹ã‚¯ã«ç•°ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚
4. **`agent_core/tool_manager.py`**: ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ«ã®ãŸã‚ã®çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã™ã€‚ãƒã‚¤ãƒ†ã‚£ãƒ– Python ãƒ„ãƒ¼ãƒ«ã¨ MCP çµŒç”±ã§æ¥ç¶šã•ã‚ŒãŸå¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚’æ¤œå‡ºãŠã‚ˆã³ç®¡ç†ã—ã¾ã™ã€‚åŒæœŸãŠã‚ˆã³éåŒæœŸã®ä¸¡æ–¹ã®ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œã‚’å‡¦ç†ã—ã¾ã™ã€‚

## ğŸš€ ã¯ã˜ã‚ã«

### å‰ææ¡ä»¶

* `Python 3.10` ä»¥ä¸Š <sub> é–‹ç™ºã§ã¯python3.12ãŒä½¿ç”¨ã•ã‚Œã¾ã—ãŸã€‚</sub>
* ãƒ¢ãƒ‡ãƒ«é«˜é€ŸåŒ–ã®ãŸã‚ã«ã€CUDA å¯¾å¿œã® NVIDIA GPU ã¾ãŸã¯ ROCm å¯¾å¿œã® AMD GPUã€‚CPU ã®ã¿ã®ãƒ¢ãƒ¼ãƒ‰ã‚‚åˆ©ç”¨å¯èƒ½ã§ã™ãŒã€GPUã¨æ¯”è¼ƒã™ã‚‹ã¨é…ããªã‚Šã¾ã™ã€‚
* `Node.js` å¤šãã®MCPã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã«å¿…è¦ã§ã™ã€‚
* `Git`

### æœ€ä½ã®æ§‹æˆã‚¹ãƒšãƒƒã‚¯
* 7.5GBä»¥ä¸Šã®ãƒ‡ã‚¹ã‚¯ç©ºãå®¹é‡
* 16GBä»¥ä¸Šã®RAMã‚‚ã—ãã¯6GBä»¥ä¸Šã®VRAM <sub> å±•é–‹ã•ã‚Œã‚‹MCPã‚µãƒ¼ãƒãƒ¼åˆ†ã®RAMã¨ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹SLMã®ãŸã‚ã®RAM or VRAMãŒå¿…é ˆã§ã™ã€‚`llama.cpp`ã®`n_ctx`ã‚’å‰Šæ¸›ã™ã‚‹ã“ã¨ã§ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã‚‹SLMã®RAMã¯æ¸›ã‚‰ã›ã¾ã™ãŒã€å‹•ä½œã«æ”¯éšœã‚’ããŸã™å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ </sub>
* `Llama-cpp-python` ãŒå¯¾å¿œã—ã¦ã„ã‚‹è¨ˆç®—ç’°å¢ƒã€‚

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

1. **ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³ã‚’ä½œæˆã—ã¾ã™:**
```bash
git clone https://github.com/username/repository.git AIagent_Project_1
cd AIagent_Project_1
```

2. **ä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™:**
ä»®æƒ³ç’°å¢ƒã®ä½¿ç”¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚
```bash
python -m venv venv
source venv/bin/activate # Windows ã§ã¯ `venv\Scripts\activate` ã‚’ä½¿ç”¨ã—ã¾ã™
pip install -r requirements.txt
```

3. **ç’°å¢ƒå¤‰æ•°ã®è¨­å®š:**
ã‚µãƒ³ãƒ—ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã« `.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã™:
```bash
cp .env.example .env
```
æ¬¡ã«ã€`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç·¨é›†ã—ã¦ API ã‚­ãƒ¼ã‚’è¿½åŠ ã—ã¾ã™:
```
# .env
GOOGLE_CUSTOM_SEARCH_API_KEY="your_google_api_key"
GOOGLE_CUSTOM_SEARCH_ENGINE_ID="your_google_cx_id"
```

### ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®å®Ÿè¡Œ

ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’èµ·å‹•ã—ã¾ã™:
```bash
python main.py
```

## ğŸ¤–ä½¿ç”¨æ–¹æ³•

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒèµ·å‹•ã—ãŸã‚‰ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§æ“ä½œã§ãã¾ã™ã€‚

* **ç›´æ¥ãƒãƒ£ãƒƒãƒˆ:**
> YOU: `ã“ã‚“ã«ã¡ã¯ã€ãŠå…ƒæ°—ã§ã™ã‹ï¼Ÿ`

* **æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰:**
> YOU: `/search LangGraph ã¨ã¯ï¼Ÿ`

* **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ (è¤‡é›‘ãªã‚¿ã‚¹ã‚¯å‘ã‘):**
> YOU: `/agentmode ãƒ“ãƒƒãƒˆã‚³ã‚¤ãƒ³ã®ç¾åœ¨ã®ä¾¡æ ¼ã‚’èª¿ã¹ã€æœ€æ–°ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’è¦‹ã¤ã‘ã¾ã™ã€‚`

* **ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’çµ‚äº†ã™ã‚‹:**
> YOu: `exit`

## ğŸ§© ã‚³ã‚¢ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

* **`main.py`**: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã€åˆæœŸåŒ–ã€ãŠã‚ˆã³ãƒ¡ã‚¤ãƒ³ã®ä¼šè©±ãƒ«ãƒ¼ãƒ—ã€‚
* **`agent_core/graph.py`**: `LangGraph` å®Ÿè¡Œã‚°ãƒ©ãƒ•ã€ãƒãƒ¼ãƒ‰ã€ã‚¨ãƒƒã‚¸ã‚’å®šç¾©ã—ã¾ã™ã€‚ã™ã¹ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã®ã‚³ã‚¢ãƒ­ã‚¸ãƒƒã‚¯ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚
* **`agent_core/state.py`**: ã‚°ãƒ©ãƒ•å†…ã®ãƒãƒ¼ãƒ‰é–“ã§æ¸¡ã•ã‚Œã‚‹çŠ¶æ…‹ã‚’è¡¨ã™ `AgentState` TypedDict ã‚’å®šç¾©ã—ã¾ã™ã€‚
* **`agent_core/llm_manager.py`**: GGUF ãƒ¢ãƒ‡ãƒ«ã®å‹•çš„ãªãƒ­ãƒ¼ãƒ‰/ã‚¢ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’å‡¦ç†ã—ã¦ VRAM ã‚‚ã—ãã¯ RAM ã‚’ç®¡ç†ã—ã¾ã™ã€‚
* **`agent_core/tool_manager.py`**: ã™ã¹ã¦ã®ãƒ„ãƒ¼ãƒ« (ãƒã‚¤ãƒ†ã‚£ãƒ–ãŠã‚ˆã³ MCP) ã®çµ±åˆå®Ÿè¡Œã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’æ¤œå‡ºã€ç®¡ç†ã€ãŠã‚ˆã³æä¾›ã—ã¾ã™ã€‚
* **`agent_core/config.py`**: ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã€ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã€ãƒšãƒ«ã‚½ãƒŠã€API ã‚­ãƒ¼ã®ä¸€å…ƒçš„ãªæ§‹æˆã€‚

## ğŸ› ï¸ ãƒ„ãƒ¼ãƒ«ã‚·ã‚¹ãƒ†ãƒ 

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯2ç¨®é¡ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚

### ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ„ãƒ¼ãƒ«

ã“ã‚Œã‚‰ã¯ã€`tool_manager.py` ã® `GoogleCustomSearchTool` ã®ã‚ˆã†ã«ã€`langchain_core.tools.BaseTool` ã‹ã‚‰ç¶™æ‰¿ã•ã‚ŒãŸ Python ã‚¯ãƒ©ã‚¹ã§ã™ã€‚ã“ã‚Œã‚‰ã¯ `ToolManager` ã«ã‚ˆã£ã¦ç›´æ¥ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚

### MCP (Multi-Server Client Protocol) ãƒ„ãƒ¼ãƒ«

ã“ã®ã‚·ã‚¹ãƒ†ãƒ ã«ã‚ˆã‚Šã€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¯åˆ¥ãƒ—ãƒ­ã‚»ã‚¹ã§å®Ÿè¡Œã•ã‚Œã‚‹ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã§ãã¾ã™ã€‚ãƒ„ãƒ¼ãƒ«ã¯ä»»æ„ã®è¨€èªã§è¨˜è¿°ã§ãã¾ã™ã€‚

1. **è¨­å®š**: `mcp_tools_config.json` ã§ãƒ„ãƒ¼ãƒ«ã‚µãƒ¼ãƒãƒ¼ã‚’å®šç¾©ã—ã¾ã™ã€‚ã‚µãƒ¼ãƒãƒ¼å®šç¾©ã¯ClaudeDesktopæ–¹å¼ã§å¯èƒ½ã§ã™ã€‚
```json
{
"mcpServers": {
"my_tool_server": {
"command": "python",
"args": ["-m", "path.to.your.tool_server"],
"env": {}
}
}
}
```
2. **æ¤œå‡º**: `ToolManager` ã¯è¨­å®šã§å®šç¾©ã•ã‚ŒãŸãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•ã—ã€`stdio` çµŒç”±ã§æ¥ç¶šã—ã€MCP ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã®ãƒ—ãƒ­ã‚»ã‚¹ãŒæä¾›ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã‚’æ¤œå‡ºã—ã¾ã™ã€‚
3. **å‘½å**: MCP ãƒ„ãƒ¼ãƒ«ã¯ã€ç«¶åˆã‚’é¿ã‘ã‚‹ãŸã‚ã€è‡ªå‹•çš„ã« `server_name_tool_name` ã¨ã„ã†åå‰ãŒä»˜ã‘ã‚‰ã‚Œã¾ã™ã€‚

## âš™ï¸ è¨­å®š

* **`.env`**: API ã‚­ãƒ¼ãªã©ã®ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’ä¿å­˜ã—ã¾ã™ã€‚ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã«ã¯ã‚³ãƒŸãƒƒãƒˆã•ã‚Œã¾ã›ã‚“ã€‚
* **`agent_core/config.py`**: ãƒ¡ã‚¤ãƒ³ã®è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ã™ã€‚
* `MODELS_GGUF`: ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹ã€ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å®šç¾©ã—ã¦ã„ã¾ã™ã€‚ç”Ÿæˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ temperature Top.P Top.K max_tokens ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå®šç¾©ã§ã™ã€‚
* `PERSONA_PROMPTS`: ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ç•°ãªã‚‹ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ãƒšãƒ«ã‚½ãƒŠã‚’å®šç¾©ã—ã¾ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯`souha_yoi`(å¥ç¾½ èŒ—ä¼Š) `bunny_girl`(ãƒãƒªãƒŠ)ã®2ç¨®é¡ãŒç”¨æ„ã•ã‚Œã¦ã„ã¾ã™ã€‚ã©ã¡ã‚‰ã‚‚æ—¥æœ¬èªã§è¨˜è¿°ã•ã‚Œã¦ã„ã‚‹ã®ã§ã€å¿…è¦ã«å¿œã˜ã¦æ›¸ãæ›ãˆã¦ãã ã•ã„ã€‚
* `ACTIVE_PERSONA`: ç¾åœ¨ã®ãƒšãƒ«ã‚½ãƒŠã‚’é¸æŠã—ã¾ã™ã€‚
* `BASE_SYSTEM_PROMPTS`: è¦ç´„ã€ReAct æ¨è«–ãªã©ã®ã‚¿ã‚¹ã‚¯ã«ãŠã‘ã‚‹ã‚³ã‚¢æ©Ÿèƒ½ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å®šç¾©ã—ã¾ã™ã€‚
* **`mcp_tools_config.json`**: å¤–éƒ¨ãƒ„ãƒ¼ãƒ«ã‚µãƒ¼ãƒãƒ¼ã‚’è¨­å®šã—ã¾ã™ã€‚

## ğŸ—ºï¸ ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

* [ ] ReActãƒ«ãƒ¼ãƒ—å†…ã«ã‚ˆã‚Šå …ç‰¢ãªã‚¨ãƒ©ãƒ¼å›å¾©ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã‚’å®Ÿè£…ã™ã‚‹ã€‚
* [ ] ã‚·ãƒ³ãƒ—ãƒ«GUIã®ä½œæˆ
* [ ] ãƒã‚¤ãƒ†ã‚£ãƒ–ãƒ„ãƒ¼ãƒ«ã¨MCPãƒ„ãƒ¼ãƒ«ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’æ‹¡å¼µã™ã‚‹ã€‚
* [ ] é•·æœŸçš„ãªä¼šè©±å±¥æ­´ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®æ°¸ç¶šãƒ¡ãƒ¢ãƒª/ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹çµ±åˆã‚’è¿½åŠ ã™ã‚‹ã€‚

## ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã«åŸºã¥ããƒ©ã‚¤ã‚»ãƒ³ã‚¹ã•ã‚Œã¦ã„ã¾ã™ã€‚è©³ç´°ã¯`LICENSE`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã”è¦§ãã ã•ã„ã€‚



